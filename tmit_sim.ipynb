{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# for simulation\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from algorithms.sgd_ts import SGD_TS\n",
    "from algorithms.UCB import UCB\n",
    "from algorithms.laplace_ts import LAPLACE_TS\n",
    "from algorithms.gloc import GLOC\n",
    "from tune import GridSearch\n",
    "from algorithms.data_processor.data_generator import * \n",
    "\n",
    "import warnings\n",
    "# silent the following warnings since that the step size in grid search set does not always offer convergence\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "# ignore the following warning since that sklearn logistic regression does not always converge on the data\n",
    "# it might be because that logistic model is not suitable for the data, this is probably the case especially for real datasets\n",
    "from  warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='simulations')\n",
    "parser.add_argument('-t', '--t', type=int, help = 'total time')\n",
    "parser.add_argument('-d', '--d', type=int, help = 'dimension')\n",
    "parser.add_argument('-k', '--k', type=int, help = 'number of arms')\n",
    "parser.add_argument('-rep', '--rep', type=int, default = 10, help = 'repeat times')\n",
    "args = parser.parse_args()\n",
    "\n",
    "T = args.t\n",
    "d = args.d\n",
    "K = args.k\n",
    "rep = args.rep\n",
    "\n",
    "ub = 1/math.sqrt(d)\n",
    "lb = -1/math.sqrt(d)\n",
    "model = 'logistic'\n",
    "dist = 'ber'\n",
    "if dist != 'ber' and model == 'logistic':\n",
    "    raise NameError('logistic regression only supports bernoulli reward')\n",
    "\n",
    "name = 'simulation_d' + str(d) + '_k' + str(K)\n",
    "if not os.path.exists('results/'):\n",
    "    os.mkdir('results/')\n",
    "if not os.path.exists('results/' + name + '/'):\n",
    "    os.mkdir('results/' + name + '/')\n",
    "\n",
    "print('K: {}, T: {}, dimension: {}, data name: {}'.format(K, T, d, name)) \n",
    "reg_sgdts = np.zeros(T)\n",
    "reg_ucbglm = np.zeros(T) \n",
    "reg_lts = np.zeros(T)\n",
    "reg_gloc = np.zeros(T)\n",
    "parameters = [\n",
    "    [(2,0.1), (5,0.01,0.1,0.1), (0.01, 0.05, 0.5), (0.5)],\n",
    "    [(1,1), (1,0.01,10,5), (1,1,0.01), (0.1)], \n",
    "    [(2,1), (1,0.5,10,0.1), (0.01, 0.5, 0.01), (0.01)],\n",
    "    [(4,0.1), (2,0.5,5,1), (0.01,0.1,1), (0.1)],\n",
    "    [(4,0.01), (1,0.01,1,0.01), (0.1,0.1,10), (0.1)],\n",
    "    [(3,1), (4,0.05,0.1,0.01), (5,1,0.01), (0.05)],\n",
    "    [(1,0.01), (5,0.1,0.01,0.01), (0.1,0.1,1), (0.1)],\n",
    "    [(1,0.1), (2,0.1,10,0.1), (1,1,0.01), (0.5)],\n",
    "    [(5,0.1), (1,0.5,0.1,5), (0.01,0.05,5), (0.1)],\n",
    "    [(3,0.01), (7,1,0.1,0.1), (0.1,0.5,0.5), (0.5)]\n",
    "]\n",
    "\n",
    "times = {\n",
    "    'ucb-glm': 0,\n",
    "    'sgd-ts': 0,\n",
    "    'gloc': 0,\n",
    "    'lts': 0\n",
    "}\n",
    "\n",
    "for i in range(rep):\n",
    "    print(i, \": \", end = \" \")\n",
    "    np.random.seed(i+1)\n",
    "    theta = np.random.normal(0.1, 1, d)\n",
    "    bandit = context(K, lb, ub, T, d, true_theta = theta)\n",
    "    bandit.build_bandit(model)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    C, explore = parameters[i][0]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    linucb = getattr(UCB(bandit, dist, T), model)\n",
    "    reg_ucbglm += linucb(tau, 10**(-6), explore)\n",
    "    times['ucb-glm'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    C, eta0, g1, g2 = parameters[i][1]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    sgd_ts = SGD_TS(bandit, model, dist, T)\n",
    "    reg_sgdts += sgd_ts.glm(eta0, tau, g1, g2)\n",
    "    times['sgd-ts'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    c, k, eta = parameters[i][2]\n",
    "    gloc = GLOC(bandit, model, dist, T)\n",
    "    reg_gloc += gloc.Gloc(c, 1, k, eta, lamda = 1, eps = 1)\n",
    "    times['gloc'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    eta0 = parameters[i][3]\n",
    "    max_ite = 1000\n",
    "    lts = LAPLACE_TS(bandit, model, dist, T)\n",
    "    reg_lts += lts.laplace_ts(1, eta0, max_ite)\n",
    "    times['lts'] += (time.time()-t0) \n",
    "    print(times)\n",
    "    # print('cost {} minutes'.format( (time.time() - t0)/60 ))\n",
    "    \n",
    "for k in times:\n",
    "    times[k] /= rep\n",
    "print('average time: ', times)\n",
    "\n",
    "result = {\n",
    "    'ucb-glm': reg_ucbglm/rep,\n",
    "    'sgd-ts': reg_sgdts/rep,\n",
    "    'gloc': reg_gloc/rep,\n",
    "    'lts': reg_lts/rep\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# for yahoo\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "from algorithms.sgd_ts import SGD_TS\n",
    "from algorithms.UCB import UCB\n",
    "from algorithms.laplace_ts import LAPLACE_TS\n",
    "from algorithms.gloc import GLOC\n",
    "from tune import GridSearch\n",
    "from algorithms.data_processor.yahoo_extract_data import extract_data\n",
    "from algorithms.data_processor.data_generator import *\n",
    "\n",
    "import warnings\n",
    "# silent the following warnings since that the step size in grid search set does not always offer convergence\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "# ignore the following warning since that sklearn logistic regression does not always converge on the data\n",
    "# it might be because that logistic model is not suitable for the data, this is probably the case especially for real datasets\n",
    "from  warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print('start processing yahoo data')\n",
    "t0 = time.time()\n",
    "if not os.path.isfile('data/rewards_yahoo.txt') or not os.path.isfile('data/features_yahoo.txt'):\n",
    "    extract_data()\n",
    "with open('data/rewards_yahoo.txt', 'rb') as f:\n",
    "    rewards = pickle.load(f)\n",
    "with open('data/features_yahoo.txt', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "print('data processing done, cost time {} seconds'.format(time.time()-t0))\n",
    "\n",
    "parser = argparse.ArgumentParser(description='experiments for yahoo data')\n",
    "parser.add_argument('-rep', '--rep', type=int, default = 10, help = 'repeat times')                  \n",
    "args = parser.parse_args()\n",
    "rep = args.rep # number of times to repeat experiments\n",
    "\n",
    "T = len(features)\n",
    "K = 20\n",
    "d = 6\n",
    "model = 'logistic'\n",
    "dist = 'ber'\n",
    "dtype = 'yahoo'\n",
    "if dist != 'ber' and model == 'logistic':\n",
    "    raise NameError('logistic regression only supports bernoulli reward')\n",
    "                                 \n",
    "print('data: Yahoo, K: around {}, T: {}, dimension: {}'.format(K, T, d))                   \n",
    "reg_sgdts = np.zeros(T)\n",
    "reg_ucbglm = np.zeros(T) \n",
    "reg_lts = np.zeros(T)\n",
    "reg_gloc = np.zeros(T)\n",
    "\n",
    "parameters = [\n",
    "    [(7,10), (7,1,0.01,0.01), (0.01, 0.05, 0.01), (0.05)]\n",
    "]\n",
    "\n",
    "times = {\n",
    "    'ucb-glm': 0,\n",
    "    'sgd-ts': 0,\n",
    "    'gloc': 0,\n",
    "    'lts': 0\n",
    "}\n",
    "\n",
    "for i in range(rep):\n",
    "    print(i, \": \", end = \" \")\n",
    "    np.random.seed(i+1)\n",
    "    bandit = yahoo(rewards, features, d)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    C, explore = parameters[i][0]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    linucb = getattr(UCB(bandit, dist, T), model)\n",
    "    reg_ucbglm += linucb(tau, 10**(-6), explore)\n",
    "    times['ucb-glm'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    C, eta0, g1, g2 = parameters[i][1]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    sgd_ts = SGD_TS(bandit, model, dist, T)\n",
    "    reg_sgdts += sgd_ts.glm(eta0, tau, g1, g2)\n",
    "    times['sgd-ts'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    c, k, eta = parameters[i][2]\n",
    "    gloc = GLOC(bandit, model, dist, T)\n",
    "    reg_gloc += gloc.Gloc(c, 1, k, eta, lamda = 1, eps = 1)\n",
    "    times['gloc'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    eta0 = parameters[i][3]\n",
    "    max_ite = 1000\n",
    "    lts = LAPLACE_TS(bandit, model, dist, T)\n",
    "    reg_lts += lts.laplace_ts(1, eta0, max_ite)\n",
    "    times['lts'] += (time.time()-t0) \n",
    "    print(times)\n",
    "    # print('cost {} minutes'.format( (time.time() - t0)/60 ))\n",
    "    \n",
    "for k in times:\n",
    "    times[k] /= rep\n",
    "print('average time: ', times)\n",
    "\n",
    "result = {\n",
    "    'ucb-glm': reg_ucbglm/rep,\n",
    "    'sgd-ts': reg_sgdts/rep,\n",
    "    'gloc': reg_gloc/rep,\n",
    "    'lts': reg_lts/rep\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from algorithms.sgd_ts import SGD_TS\n",
    "from algorithms.UCB import UCB\n",
    "from algorithms.laplace_ts import LAPLACE_TS\n",
    "from algorithms.gloc import GLOC\n",
    "from tune import GridSearch\n",
    "from algorithms.data_processor.data_generator import * \n",
    "\n",
    "import warnings\n",
    "# silent the following warnings since that the step size in grid search set does not always offer convergence\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "# ignore the following warning since that sklearn logistic regression does not always converge on the data\n",
    "# it might be because that logistic model is not suitable for the data, this is probably the case especially for real datasets\n",
    "from  warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='experiments for cover type data')\n",
    "parser.add_argument('-rep', '--rep', type=int, default = 10, help = 'repeat times')\n",
    "parser.add_argument('-t', '--t', type=int, help = 'total time')\n",
    "parser.add_argument('-d', '--d', type=int, default = 10, help = 'number of features, choice of 10 (not use categorical features), 55 (use cat)')\n",
    "parser.add_argument('-center', '--center', type=int, default = 1, help = 'use centriods as features')\n",
    "parser.add_argument('-add', '--add', type=int, default = 0, help = 'add a constant column feature')\n",
    "\n",
    "args = parser.parse_args()\n",
    "rep = args.rep  # repeat times, set to 10\n",
    "T = args.t  # total rounds, set to 1000\n",
    "d = args.d  # feature dimension, if use only quantitative features, d = 10, otherwise, d = 55\n",
    "center = args.center # if center == 1, use cluster centroid as features, if center == 0, use random features\n",
    "add_constant = args.add # add_constant = 1 to add a constant feature to the data\n",
    "d += add_constant\n",
    "\n",
    "####\n",
    "d = 56\n",
    "center = 0\n",
    "####\n",
    "\n",
    "if center == 1:\n",
    "    print('use cluster centroid as features, d = {},'.format(d), 'start processing data')\n",
    "if center == 0:\n",
    "    print('use random features, d = {},'.format(d), 'start processing data')\n",
    "    \n",
    "# extract, centeralize, standardize and cluster cover type data\n",
    "lines = []\n",
    "labels = []\n",
    "t0 = time.time()\n",
    "# save the 'covtype.data.gz' under the 'data' folder before running this code\n",
    "with gzip.open('data/covtype.data.gz', \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.split(b',')\n",
    "        tmp = line[:d]\n",
    "        y = int(line[-1])\n",
    "        if y!=1:\n",
    "            y = 0\n",
    "        x = [float(i) for i in tmp]\n",
    "        lines += [x]\n",
    "        labels += [y]\n",
    "\n",
    "X = np.array(lines)\n",
    "y = np.array(labels)\n",
    "X[:,:10] = preprocessing.scale(X[:,:10])\n",
    "if add_constant == 1:\n",
    "    X_add = np.ones((X.shape[0],X.shape[1]+1))\n",
    "    X_add[:,:-1] = X\n",
    "else:\n",
    "    X_add = X\n",
    "\n",
    "np.random.seed(0)\n",
    "kmeans = KMeans(n_clusters=32, random_state=0).fit(X_add)\n",
    "rewards = [0]*32\n",
    "idx = [None for _ in range(32)]\n",
    "features = np.array(kmeans.cluster_centers_)\n",
    "for nc in range(32):\n",
    "    idx[nc] = np.where(kmeans.labels_ == nc)[0]\n",
    "    num, den = sum(y[idx[nc]]), len(idx[nc])\n",
    "    rewards[nc] = num / den\n",
    "bandit_data = (X_add, y, idx)\n",
    "K, d = 32, X_add.shape[1]\n",
    "\n",
    "# the following code and function sort the reward and calculate the frequencies for the pulls of best 6 arms\n",
    "rew = sorted(rewards, reverse = True)\n",
    "gap = dict()\n",
    "for i in range(32):\n",
    "    gap[round(rew[0] - rew[i],4)] = i\n",
    "def frequency(regr):\n",
    "    fre = [0] * 32\n",
    "    pulled = gap[round(regr[0],4)]\n",
    "    fre[pulled] += 1\n",
    "    for t in range(1, len(regr)):\n",
    "        r = round(regr[t] - regr[t-1], 4)\n",
    "        pulled = gap[r]\n",
    "        fre[pulled] += 1\n",
    "    return fre\n",
    "print('data process done, cost in total {} seconds'.format(time.time()-t0))\n",
    "print('max reward = {}, min reward = {}'.format(max(rewards), min(rewards)))\n",
    "print('feature vectors shape: K={}, d={}'.format(K,d))\n",
    "\n",
    "model = 'logistic'\n",
    "dist = 'ber'\n",
    "if dist != 'ber' and model == 'logistic':\n",
    "    raise NameError('logistic regression only supports bernoulli reward')\n",
    "\n",
    "\n",
    "print('K: {}, T: {}, dimension: {}, model: {}, dist: {}'.format(K, T, d, model, dist)) \n",
    "reg_sgdts = np.zeros(T)\n",
    "reg_ucbglm = np.zeros(T) \n",
    "reg_lts = np.zeros(T)\n",
    "reg_gloc = np.zeros(T)\n",
    "fre_sgdts = []\n",
    "fre_lts = []\n",
    "fre_ucbglm = []\n",
    "fre_gloc = []\n",
    "parameters = [\n",
    "    [(2,1), (1,0.05,1,0.01), (0.01, 0.05, 0.01), (0.01)]\n",
    "]\n",
    "\n",
    "times = {\n",
    "    'ucb-glm': 0,\n",
    "    'sgd-ts': 0,\n",
    "    'gloc': 0,\n",
    "    'lts': 0\n",
    "}\n",
    "\n",
    "for i in range(rep):\n",
    "    print(i, \": \", end = \" \")\n",
    "    np.random.seed(i+1)\n",
    "    if center:\n",
    "        bandit = covtype(rewards, features, T, d)\n",
    "    else:\n",
    "        bandit = covtype_random_feature(rewards, bandit_data, T, d)\n",
    "        bandit.build_bandit()  \n",
    "        \n",
    "    t0 = time.time()\n",
    "    C, explore = parameters[i][0]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    linucb = getattr(UCB(bandit, dist, T), model)\n",
    "    reg_ucbglm += linucb(tau, 10**(-6), explore)\n",
    "    times['ucb-glm'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    C, eta0, g1, g2 = parameters[i][1]\n",
    "    tau = int(max(d, math.log(T)) * C)\n",
    "    sgd_ts = SGD_TS(bandit, model, dist, T)\n",
    "    reg_sgdts += sgd_ts.glm(eta0, tau, g1, g2)\n",
    "    times['sgd-ts'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    c, k, eta = parameters[i][2]\n",
    "    gloc = GLOC(bandit, model, dist, T)\n",
    "    reg_gloc += gloc.Gloc(c, 1, k, eta, lamda = 1, eps = 1)\n",
    "    times['gloc'] += (time.time()-t0) \n",
    "    \n",
    "    t0 = time.time()\n",
    "    eta0 = parameters[i][3]\n",
    "    max_ite = 1000\n",
    "    lts = LAPLACE_TS(bandit, model, dist, T)\n",
    "    reg_lts += lts.laplace_ts(1, eta0, max_ite)\n",
    "    times['lts'] += (time.time()-t0) \n",
    "    print(times)\n",
    "\n",
    "for k in times:\n",
    "    times[k] /= rep\n",
    "print('average time: ', times)\n",
    "\n",
    "result = {\n",
    "    'ucb-glm': reg_ucbglm/rep,\n",
    "    'sgd-ts': reg_sgdts/rep,\n",
    "    'gloc': reg_gloc/rep,\n",
    "    'lts': reg_lts/rep\n",
    "}\n",
    "\n",
    "frequent = {\n",
    "    'ucb-glm': fre_ucbglm,\n",
    "    'sgd-ts': fre_sgdts,\n",
    "    'gloc': fre_gloc,\n",
    "    'lts': fre_lts\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
